#!/usr/bin/env python

import sys
from optparse import OptionParser, Values

from ONTraC.analysis.anndata import anndata_based_analysis
from ONTraC.analysis.train_loss import plot_train_loss
from ONTraC.analysis.utils import *
from ONTraC.data import load_dataset
from ONTraC.log import *
from ONTraC.run.processes import load_data
from ONTraC.utils import *


def analysis_pipeline(options: Values, rel_params: Dict) -> None:
    # 0. prepare data
    # load data
    dataset, data = load_dataset(options=options)

    # 1. trainging loss
    plot_train_loss(options)
    # 2. soft assignment plots
    plot_max_pro_cluster(options, data)
    plot_each_cluster_proportion(options, data)
    # 3. cluster spatial continuity
    cluster_spatial_continuity(options, data)
    # 4. AnnData based analysis
    # meta_df = anndata_based_analysis(options, data)
    # if meta_df is not None:
    #     # 5. compare pseudo time
    #     compare_pseudo_time(options, meta_df)
    #     # 6. cell type distribution
    #     cell_type_dis_in_cluster(options, data, meta_df)
    #     # 7. niche max proportion
    #     niche_max_dis_in_cluster(options, data, meta_df)
    #     # 8. pseudo time in each cell type
    #     pseudotime_in_each_cell_type(options, meta_df)
    # # 9. cluster connectivity
    # cluster_connectivity(options)

    # if options.process:
    #     # 10. process
    #     process_analysis(options=options, dataset=dataset, data=data)


def prepare_optparser() -> OptionParser:
    """Prepare optparser object. New options will be added in this function first.

    Ret: OptParser object.
    """
    usage = "usage: %prog <-n NAME> <-i INPUT>"
    description = "Analysis the results of ONTraC."
    optparser = OptionParser(usage=usage, description=description, add_help_option=False)
    optparser.add_option('-h', '--help', action='help', help='Show this help message and exit.')
    optparser.add_option('-n', '--name', dest='name', type='string', help='Name of the train.')
    optparser.add_option(
        '-i',
        '--input',
        dest='input',
        type='string',
        help='Directory contains input dataset. This directory should be the output directory of createDataSet.')
    optparser.add_option('-y', '--yaml', dest='yaml', type='string', help='Yaml file stored dataset information.')
    optparser.add_option('-p',
                         '--process',
                         dest='process',
                         action='store_true',
                         default=False,
                         help='Analysis intermediate results generated in training process.')
    return optparser


def opt_validate(optparser: OptionParser) -> Values:
    """Validate options from a OptParser object.

    Args:
        optparser: OptParser object.
    """
    (options, args) = optparser.parse_args()
    if not options.input:
        optparser.print_help()
        sys.exit(1)
    options.output = f'output/{options.name}'
    if not options.output:
        error(f'Output directory for training not found: {options.output}')
        optparser.print_help()
        sys.exit(1)
    if not os.path.exists(options.yaml):
        error(f'Yaml file not found: {options.yaml}')
        optparser.print_help()
        sys.exit(1)
    options.device = 'cpu'

    return options


def main():
    optparser = prepare_optparser()
    options = opt_validate(optparser)
    params = read_yaml_file(options.yaml)
    options.data = rel_params = get_rel_params(options, params)

    analysis_pipeline(options, rel_params)


if __name__ == '__main__':
    main()
