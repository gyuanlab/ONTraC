#!/usr/bin/env python

import sys
from optparse import OptionParser, Values

from ONTraC.analysis.anndata import anndata_based_analysis
from ONTraC.analysis.cell_type import (NTScore_in_each_cell_type,
                                       cell_type_dis_in_cluster)
from ONTraC.analysis.train_loss import plot_train_loss
from ONTraC.analysis.utils import *
from ONTraC.data import load_dataset
from ONTraC.log import *
from ONTraC.optparser._IO import add_IO_options_group, validate_io_options
from ONTraC.run.processes import load_data
from ONTraC.utils import *

# ------------------------------------
# Constants
# ------------------------------------
IO_OPTIONS = ['dataset', 'preprocessing_dir', 'GNN_dir', 'NTScore_dir']


# ------------------------------------
# Functions
# ------------------------------------
def analysis_pipeline(options: Values, rel_params: Dict) -> None:
    # 0. prepare data
    # load data
    dataset, data = load_dataset(options=options)

    # 1. trainging loss
    plot_train_loss(options)
    # 2. soft assignment plots
    plot_max_pro_cluster(options, data)
    plot_each_cluster_proportion(options, data)
    # 3. cluster spatial continuity
    cluster_spatial_continuity(options, data)
    # 4. AnnData based analysis
    try:
        meta_df = anndata_based_analysis(options, data)
    except Exception as e:
        error(f'Error in AnnData based analysis: {e}')
        meta_df = None
    if meta_df is not None:
        # 5. cell type distribution
        cell_type_dis_in_cluster(options, data, meta_df)
        # 6. NT Score in each cell type
        NTScore_in_each_cell_type(options, meta_df)
    # 7. cluster connectivity
    cluster_connectivity(options)

    # if options.process:
    #     # 10. process
    #     process_analysis(options=options, dataset=dataset, data=data)


def prepare_optparser() -> OptionParser:
    """Prepare optparser object. New options will be added in this function first.

    Ret: OptParser object.
    """
    usage = "usage: %prog <-d DATASET> <--preprocessing-dir PREPROCESSING_DIR> <--GNN-dir GNN_DIR> <--NTScore-dir NTSCORE_DIR> <-l LOG_FILE> <-o OUTPUT_DIR>"
    description = "Analysis the results of ONTraC."
    optparser = OptionParser(usage=usage, description=description, add_help_option=False)
    optparser.add_option('-h', '--help', action='help', help='Show this help message and exit.')
    optparser.add_option('-o', '--output', dest='output', type='string', help='Output directory.')
    optparser.add_option('-l', '--log', dest='log', type='string', help='Log file.')
    add_IO_options_group(optparser=optparser, io_options=IO_OPTIONS)
    return optparser


def opt_validate(optparser: OptionParser) -> Values:
    """Validate options from a OptParser object.

    Args:
        optparser: OptParser object.
    """
    (options, args) = optparser.parse_args()

    validate_io_options(optparser, options, IO_OPTIONS)

    if not options.log:
        error('Log file is required.')
        sys.exit(1)
    if not os.path.exists(options.log):
        error(f'Log file not found: {options.log}')
        sys.exit(1)

    options.yaml = f'{options.preprocessing_dir}/params.yaml'
    if not os.path.exists(options.yaml):
        error(f'File not found: {options.yaml}')
        sys.exit(1)
    options.device = 'cpu'

    return options


def main():
    optparser = prepare_optparser()
    options = opt_validate(optparser)
    params = read_yaml_file(options.yaml)
    options.data = rel_params = get_rel_params(options, params)

    analysis_pipeline(options, rel_params)


if __name__ == '__main__':
    main()
